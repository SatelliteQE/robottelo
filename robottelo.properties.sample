# Make a copy of this file named robottelo.properties
[server]
# Server hostname
hostname=
# Additional satellite hostnames for xdist workers
# gw0=
# gw1=
# gw2=

# Path to private ssh key to be used when connecting via SSH.
ssh_key=

# HTTP scheme when building the server URL
# Suggested values for "scheme" are "http" and "https".
# scheme=https

# Server port
# port=443

# SSH username
# ssh_username=root

# SSH password if not using a SSH key to connect
# ssh_password=

# Admin username when accessing API and UI
# admin_username=admin

# Admin password when accessing API and UI
# admin_password=changeme

# section for ssh client settings
# [ssh_client]
# Time to wait for the ssh command to finish, in seconds
# command_timeout=300
# Time to wait for establishing the ssh connection, in seconds
# connection_timeout=10

# Override robottelo configuration
[robottelo]
# The directory where screenshots will be saved.
# Note:- Content under /tmp may be deleted after a reboot.
# screenshots_path=/tmp/robottelo/screenshots/
# locale=en_US.UTF-8
# Update upstream=false for downstream run
# upstream=true
# Logging verbosity, one of debug, info, warning, error, critical
# verbosity=debug
# Directory for temporary files
# tmp_dir=/var/tmp
# Web Server to provide various test artifacts
# artifacts_server=server.example.com
# Webdriver logging options
# A list of commands to be logged
# log_driver_commands=newSession,windowMaximize,get,findElement,sendKeysToElement,clickElement,mouseMoveTo
# - The URL of container hosting repos on SatLab
# Example url - http://<container_hostname_or_ip>:<port>
# Use https://github.com/SatelliteQE/fedorapeople-repos to deploy and configure the repos hosting container
# repos_hosting_url=

# browser tells robottelo which browser to use when testing UI. Valid values
# are:
# * selenium
# * docker: to use a browser inside a docker container. In order to use this
#   feature make sure that the docker daemon is running locally and has its
#   unix socket published at unix://var/run/docker.sock. Also make sure that
#   the docker image selenium/standalone-firefox is available.
# * saucelabs: makes robottelo run tests on SauceLabs. The saucelabs_user and
#   saucelabs_key are required and the browser used is the same specified on
#   webdriver.  Supported values for webdriver are firefox, chrome and ie, the
#   other valid webdriver values are going to be translated to firefox.
# * remote: to access the remote browser, the webdriver and command_executor
#   are required.
# browser=selenium

# Webdriver to use. Valid values are chrome, firefox, ie, edge, phantomjs
# webdriver=chrome

# Run browser for UI tests with semicolon delimeted options such as headless. Currently supported for only chrome.
# browseroptions=

# Binary location for selected wedriver (not needed if using saucelabs)
# webdriver_binary=/usr/bin/firefox
# webdriver_binary=/usr/bin/chromedriver
# webdriver_binary=C:\\Program Files (x86)\\Microsoft Web Driver\\MicrosoftWebDriver.exe

# webdriver_desired_capabilities accepts extra configuration to be passed to
# saucelabs in order to configure the test options. You can use the platform
# configurator (see link below) to get the information about the environment
# you want to test.
# https://wiki.saucelabs.com/display/DOCS/Platform+Configurator/
# Or you can visit
# https://wiki.saucelabs.com/display/DOCS/Test+Configuration+Options for a
# complete set of options.
# PS.: the base DesiredCapabilities dict will be get by the browser
# specified by webdriver config. If you override browserName then that
# browser will be used instead.
# examples:
# (note: version=<browser version>)
# webdriver_desired_capabilities=platform=OS X 10.9,version=45.0,build=myBuildName,parentTunnel=otherUser,seleniumVersion=2.48.0
# webdriver_desired_capabilities=platform=macOS 10.12,version=45.0,build=myBuildName,seleniumVersion=2.48.0,screenResolution=1600x1200
# webdriver_desired_capabilities=platform=Windows 10,version=14.14393,build=myBuildName,seleniumVersion=2.48.0,screenResolution=1600x1200
# webdriver_desired_capabilities=platform=Linux,browserName=chrome,unhandledPromptBehavior=dismiss,unexpectedAlertBehaviour=ignore,acceptInsecureCerts=True
# command_executor=http://127.0.0.1:4444/wd/hub

# saucelabs_user=
# saucelabs_key=

# cdn=true
# Run one datapoint or multiple datapoints for tests
# run_one_datapoint=false

# Provide link to rhel6/7 repo here, as puppet rpm would require packages from
# RHEL 6/7 repo and syncing the entire repo on the fly would take longer for
# tests to run Specify the *.repo link to an internal repo for tests to execute
# properly
# rhel6_repo=http://example.com/yum/repo_files/rhel6-updates.repo
# rhel7_repo=http://example.com/yum/repo_files/rhel7-updates.repo
# rhel8_repo=http://example.com/yum/repo_files/rhel8-updates.repo

# Provide link to rhel6/7 repositories URL as we need all OS packages in order
# to have real installation media for provisioning procedure
# rhel6_os=http://example.com/yum/rhel6-os/
# rhel7_os=http://example.com/yum/rhel7-os/

# RHEL 8 repos
# rhel8_os=baseos=http://example.com/rhel-8/BaseOS/x86_64/os/,appstream=http://example.com/rhel-8/AppStream/x86_64/os/


# If capsule and satellite tools repositories available related packages will
# be pulled from there instead of using the CDN channel. These information is
# more suited to be used for downstream, downstream-iso and zstream builds.
# capsule_repo=http://capsule/repo
# sattools_repo=
#   rhel6=http://sattools/repo/el6,
#   rhel7=http://sattools/repo/el7,

# Added swid_tools_repo for installing swid-tools and dnf-plugin-swidtags packages
# which are essentially required for generating swid tags in RHEL8 content host.
# swid_tools_repo=https://example.com/swid-rhel-8.repo

# Broker-specific settings
# [broker]
# broker_directory=.

# Bugzilla data to authenticate API calls
# [bugzilla]
# url default value is set to 'https://bugzilla.redhat.com' even if not provided.
# url=https://bugzilla.redhat.com

# Provide api_key to access Bugzilla REST API
# api_key=

# For Open Ldap Authentication
# [open_ldap]
# hostname=
# username=
# open_ldap_user=
# password
# base_dn=
# group_base_dn=

# For LDAP Authentication.
# [ldap]
# hostname=
# username=
# password=
# basedn=
# grpbasedn=
# realm=
# nameserver=

# For LDAP freeIPA Authentication.
# [ipa]
# hostname_ipa=
# username_ipa=
# password_ipa=
# basedn_ipa=
# grpbasedn_ipa=
# user_ipa=
# disabled_user_ipa=
# otp_user=otp_user
# time_based_secret=
# group_users =
# groups =

# Fake manifest testing.
# [fake_manifest]
# Comma-separated list of urls for multiple manifests
# e.g. url=name1=http://url/1,name2=http://url/2,...
# url=http://url is supported for backward compatibility and is equal to:
# url=default=http://url
# URL of the key file
# key_url=http://example.org/fake_manifest.key
# URL of the certificate file
# cert_url=http://example.org/fake_manifest.crt

# Client provisioning for tests that require client machines
# [clients]
# Provisioning server hostname where the clients will be created
# provisioning_server=
# Comma separated list of distributions, see robottelo/constants.py::DISTRO_*
# distros=rhel6, rhel7

# Path on the provisioning server where the virtual images will be stored. If
# not specified in the configuration, the default libvirt path will be used
# "/var/lib/libvirt/images/". Make sure that the path exists on the
# provisioning server.
# image_dir=/opt/robottelo/disks


# For tests that uses the images for content-host testcases.
# [distro]
# image_el6=rhel610
# image_el7=rhel77
# image_el8=rhel80
# image_sles11=sles-11-4
# image_sles12=sles-12-3


# For tests that uses the docker feature
# [docker]
# Name of the libvirt image containing the OS with docker instance set up
# Each test involving external docker instance will instantiate a new VM
# requires [clients] section.
# docker_image=rhel7-docker-base
# This will be used by tests that exercise external docker registries.
# External docker registry url in the format http[s]://<server>[:<port>].
# external_registry_1=
# For testing the support for private registry repos
# private_registry_url='https://registry.hub.docker.com'
# private_registry_name=username/imagename
# private_registry_username=
# private_registry_password=


# VLAN Networking details
# These settings are required for compute resources testing, for example
# host provisioning on CR's, discovery e.t.c.
# Make sure you have also provided the necessary compute_resources information.
# [vlan_networking]
# subnet=SUBNET_VALUE
# netmask=NETMASK_VALUE
# bridge=BRIDGE_VALUE
# gateway=GATEWAY_VALUE
# dhcp_ipam=DHCP|INTERNAL DB
# dhcp_from=IP_RANGE_FROM
# dhcp_to=IP_RANGE_TO
# dns_primary=IP_OF_DNS_SERVER
# dns_zone=DNS_ZONE_NAME
# network=NETWORK_VALUE (mutually exclusive with bridge)

# For discovery ISO
# Discovery ISO name is required for PXE-less discovery tests. ISO's are
# rebuilt with extra kernel options for unattended pxe-less discovery
# ISO file names should be like below for downstream_el6 and el7 environments:
# foreman-discovery-image-3.0.5-3_unattended_down_el7.iso
# foreman-discovery-image-3.0.5-3_unattended_down_el6.iso
# [discovery]
# discovery_iso=DISCOVERY_ISO

# For OSCAP Testing
# [oscap]
# content_path=~/ssg-rhel6-ds.xml
# tailoring_path=~/ssg-firefox-ds-tailoring.xml

# For katello-certs-check utility
# [certs]
# CERT_FILE=~/certs/server.valid.crt
# KEY_FILE=~/certs/server.key
# REQ_FILE=~/certs/server.csr
# CA_BUNDLE_FILE=~/certs/rootCA.pem

# Section for performance tests parameters.
# [performance]
# Control whether or not to time on hammer commands in robottelo/cli/base.py
# Default set to be 0, i.e. no timing of performance is measured and thus no
# interference to original robottelo tests.
# time_hammer=false

# Folowing entries are used for preparation of performance tests after a fresh
# install. They will be used by
# `test/foreman/performance/test_standard_prep.py`, which supports:
#
# 1. downloading manifest,
# 2. uploading manifest to subscription,
# 3. updating Red Hat CDN URL,
# 4. enabling key repositories: rhel6-rpms, rhel7-rpms, rhel6-kickstart-rpms,
#    rhel7-kickstart-rpms, rhel6-optional-rpms, rhel7-optional-rpms,
#    rhel6-optional-source-rpms, rhel7-optional-source-rpms,
#    rhel6-optional-debug-rpms, r7-optional-debug-rpms
#
# Note that this preparation step is not required as long as satellite server
# is already configured.
# cdn_address=http://cdn.example.com/pub

# A list of VM IP addresses or hostnames. Each system should already be
# provisioned. They will be used in concurrent system subscription tests.
# virtual_machines=127.0.0.1,127.0.0.1,127.0.0.1,127.0.0.1,127.0.0.1

# Savepoint utility to restore the database. For example, after conducting
# 5,000 concurrent subscription by activation-key using 10 clients, in order to
# start next 5k test case of subscription by register and attach, the
# performance test would restore the database back to the state where there's
# no client registered. All performance test cases would use this setting
#
# User should create savepoint-1 immediately after a fresh installation of
# Satellite.
# fresh_install_savepoint=

# User should create savepoint-2 after enabling repositories, but before
# any system subscription or repository synchronization.
# enabled_repos_savepoint=

# Parameter for number of buckets to be sliced by csv generating function
# Class `ConcurrentTestCase` and its subclasses use this setting when
# computing statistics of each performance test case, grouped in buckets.
# csv_buckets_count=10

# Target repository names to be synchronized by Pulp.
# Target repositories are subset of all enabled repositories.
# Real repository names should be referred by
# `h repository list --organization-id=1`
# target_repos=RHEL 6 Kickstart rpms,RHEL 6 Optional Source rpms

# Number of times to repeat synchronization on each repository
# sync_count=3

# Parameter for deciding whether conduct initial sync or resync
# 'resync' denotes resync; 'sync' denotes initial sync
# sync_type='sync'

# Compute Resources
# [compute_resources]
# External Libvirt Hostname
# libvirt_hostname=

# Path on the Libvirt host, where the virtual images will be stored.
# The default libvirt image dir will be used
# "/var/lib/libvirt/images/".
# libvirt_image_dir=/var/lib/libvirt/images

# Section for Upgrade Scenarios Verification Tests
[upgrade]
# RHEVM capsule hostname
# rhev_cap_host=
# Custom capsule hostname
# capsule_hostname=
# RHEVM capsule activation key
# rhev_capsule_ak=
# Custom capsule activation key
# capsule_ak=
# The satellite end version
# to_version=6.6
# The satellite from version
# from_version=
# The docker host onto wich the chost containers will be spawned
# docker_vm=
# The upgrade VLAN vm_domain
# vm_domain=

# section for fake capsule setup.
[fake_capsules]
# a range of ports configured for capsule port mapping represented by a tuple:
#<int>, <int> (no brackets)
# for RHEL7 - the ports needs to have a correct selinux context set:
# 'semanage port -a -t websm_port_t -p tcp <port-range>'
port_range=9091, 14999

# [azurerm]
# Azure Resource Manager(AzureRM) Provider as Compute Resource
# Client ID of the AzureRM account
# client_id=
# Client Secret of the AzureRM account
# client_secret=
# The subscription ID is a GUID that uniquely identifies your subscription to use Azure services.
# subscription_id=
# Tenant ID, the ID of the AAD directory in which you created the application
# tenant_id=
# Azure Region
# azure_region=
# SSH Public Key of the user from which login as passwordless in VM
# ssh_pub_key=
# Username of admin user(non-root)
# username=
# Password of the admin user
# password=
# Azure Private subnet details
# azure_subnet=

# [ec2]
# AWS EC2 to be added as a compute resource.
# Access key ID of the IAM user
# access_key=
# Secret access key of the IAM user
# secret_key=
# The default AWS region for the compute resources
# by default US West (Oregon)
# region=us-west-2
# The default compute resource profile image
# image=
# The default compute resource profile availability zone set it empty if no
# preferences
# availability_zone=eu-west-2a
# default
# The default compute resource profile subnet set it empty if no preferences
# subnet=172.31.0.0/20
# The default compute resource profile security groups (comma separated list)
#  default value is default
# security_groups=default
# The default compute resource profile security managed ip available values Private, Public
# default value is private
# managed_ip=Private

#[gce]
# Google Provider as Compute Resource
# Project name in Google provider
#project_id=sat6qe
# Service Account email id which has compute admin permission
#client_email=
# client json Certificate path which is local path on satellite
#cert_path=/usr/share/foreman/sat6qetester_key.json
# Zones
#zone=
# client certificate URL
#cert_url=

# [rhev]
# RHEV to be added as a compute resource.
# hostname: RHEV API URL, for example: https://ovirt.example.com/api
# hostname=
# username: Login for RHEVM
# username=
# password: Password for RHEVM
# password=
# datacenter: RHEVM datacenter, for example: Default
# datacenter=
# vm_name: Name of VM to power On/Off & delete
# vm_name=
# storage_domain: VM storage domain, possible values NFS-BOS, NFS-SATENG, VMS,
# default value NFS-BOS
# storage_domain=NFS-BOS

# RHEV Compute resource image data
# image_os: Operating system of the image
# image_os=
# image_arch: Architecture of the image
# image_arch=
# image_username: Login to the image
# image_username=
# image_password: Password to the image
# image_password=
# image_name: Image name on the external provider
# image_name=
# image_uuid: Unique image id
# image_uuid=
# RHV CA cert url for adding RHV as compute resource
# ca_cert=

# [vmware]
# Vmware to be added as a compute resource
# vcenter: vmware vcenter URL
# vcenter=
# username: Login for vmware
# username=
# password: Password for vmware
# password=
# datacenter: vmware datacenter
# datacenter=
# vm_name: Name of VM to power On/Off & delete
# vm_name=

# Vmware Compute resource image data
# image_os: Operating system of the image
# image_os=
# image_arch: Architecture of the image
# image_arch=
# image_username: Login to the image
# image_username=
# image_password: Password to the image
# image_password=
# image_name: Image name on the external provider
# image_name=

# [osp]
# Openstack to be added as a compute resource
# hostname: Openstack api url For eg: https://hostname:port/v2.0/tokens
# hostname=
# username: Login for Openstack
# username=
# password: Password for Openstack
# password=
# tenant: Openstack tenant to be used
# tenant=
# project_domain_id: OpenStack project domain ID
# project_domain_id=
# security_group: Name of group for provisioning
# security_group=
# vm_name: Name of VM to power On/Off & delete
# vm_name=

# Openstack Compute resource image data
# image_os: Operating system of the image
# image_os=
# image_arch: Architecture of the image
# image_arch=
# image_username: Login to the image
# image_username=
# image_name: Image name on the external provider
# image_name=

# section for real capsule
# [capsule]
# to setup a real capsule we need the capsule virtual machine hostname
# resolvable.
# we should register a hostname and get a hash value that we should use on the
# stage of ddns setup
# domain is the base ddns domain, the virtual machine hostname will be a sub
# domain of this domain.
# domain=
# the instance_name is the key used in the registration above, and used to name
# the instance of the virtual machine
# the real finale hostname should be instance_name.domain
# instance_name=
# the hash is the hash value returned in ddns registration
# hash=
# ddns rpm package to install on the virtual machine to setup ddns hostname
# resolution
# ddns_package_url=

# Section for shared function
# [shared_function]
# The default storage handler to use, available handlers: file, redis
# by default storage=file
# storage=file
# Namespace scope by default used the md5 of kattelo certificate of the server
# scope=
# enabled, by default enabled=false, the shared decorator will
# immediately run the function and the function result data are not saved
# to enable the shared functionality set enabled=true
# enabled=false
# The lock timeout, to be able to use the shared data, each caller have to lock
# the access to storage to have consistent values, by default 2 hours, to be
# able to handle long running functions, the value is in second
# lock_timeout=7200
# How much time the shared data is considered valid, the value is in second
# by default 24 hours
# share_timeout=86400
# If redis is used as storage, by default redis_host=localhost
# redis_host=localhost
# The port redis is accessible at that redis_host, by default 6379
# redis_port=6379
# The redis db index, by default 0
# redis_db=0
# The redis password index, by default None
# redis_password=
# How much time we retry if a function call fail, by default call_retries=2
# call_retries=2

# Section for virtwho configure function
# [virtwho]
# The hypervisor type, one of the values: esx, xen, hyperv, rhevm, libvirt, kubevirt
# hypervisor_type=
# The hostname or ip or other values for hypervisor server, depends on the type
# hypervisor_server=
# Admin username to access hypervisor server
# hypervisor_username=
# Admin password to access hypervisor server
# hypervisor_password=
# The config file to connect hypervisor, only for kubevirt
# hypervisor_config_file=
# The guest ip or hostname in the hypervisor
# guest=
# The guest port for ssh connection, by default guest_port=22
# guest_port=22
# ssh username to access guest
# guest_username=
# ssh password to access guest
# guest_password=
# The SKU ID for physical vdc
# sku_vdc_physical=
# The SKU ID for virtual vdc
# sku_vdc_virtual=

# section for RH-SSO integration
# [rhsso]
# RH-SSO Hostname
# host_name=
# RH-SSO Host Url
# host_url=
# RH-SSO Host Admin of Realm
# rhsso_user=
# RH-SSO Host Admin Password
# user_password=
# RH-SSO Host Realm
# realm=
# TOTP Secret
totp_secret=

# Report Portal Section for Rerunning failed tests
# [report_portal]
# Portal URL
# portal_url=
# Project Name
# project=satellite6
# API key of an user
# api_key=
# To skip the rerun, if the failed tests in last run more than fail_threshold %
# if its not set, 20% by default will be considered
# fail_threshold=

# Section for Http Proxy Details
# [http_proxy]
# un_auth_proxy_url=http://proxy.example.com:4332
# auth_proxy_url=
# username=
# password=
